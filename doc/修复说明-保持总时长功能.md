# 修复说明：保持总时长功能

## 🔧 修复内容

### 1. TimelineAdjuster - 增强压缩逻辑

**文件**：`src/scripts/timeline_adjuster.py`

**修改**：`_compress_timeline` 方法

**新增功能**：
- 当静音间隙不足以吸收时长差异时，自动加速配音
- 保存 `original_duration_ms` 和 `adjusted_duration_ms` 到字幕数据中
- 确保最终总时长 = 原始SRT总时长

**处理流程**：
```
1. 计算静音间隙总时长
   ↓
2. 如果间隙足够 → 按比例压缩间隙
   ↓
3. 如果间隙不足 → 移除所有间隙 + 加速配音
   ↓
4. 输出调整后的时间轴（总时长 = 原始SRT总时长）
```

### 2. TTSDubbingProcessor - 修复音频合并逻辑

**文件**：`src/scripts/tts_dubbing_processor.py`

**修改**：`_merge_audio_with_timeline` 方法

**新增功能**：
- 读取 `original_duration_ms` 和 `adjusted_duration_ms`
- 根据这两个值判断是否需要加速音频
- 使用FFmpeg高质量加速音频
- 确保最终音频时长匹配调整后的时间轴

**处理流程**：
```
1. 遍历每个字幕
   ↓
2. 检查 original_duration_ms vs adjusted_duration_ms
   ↓
3. 如果需要加速 → 使用FFmpeg加速音频
   ↓
4. 确保音频时长 = adjusted_duration_ms
   ↓
5. 合并所有音频片段
```

## 📊 预期效果

### 场景1：配音超出原始时长（需要加速）

**输入**：
```
原始SRT总时长: 115000ms (1:55)
配音总时长: 152000ms (2:32)
静音间隙总时长: 5000ms
```

**处理过程**：
```
⏱️  开始动态调整时间轴
原始总时长: 115000ms

  字幕 1: 原时长=2000ms, 实际配音=3500ms, 差异=+1500ms
  字幕 2: 原时长=2500ms, 实际配音=4200ms, 差异=+1700ms
  ...

总配音时长: 152000ms
时长差异: +37000ms

  原始间隙总时长: 5000ms
  需要压缩: 37000ms
  ⚠️ 间隙不足，移除所有间隙后仍超出 32000ms
  🚀 需要加速配音以压缩 32000ms
  
  📊 配音总时长: 152000ms
  📊 目标时长: 120000ms
  📊 加速倍率: 1.27x
  
  字幕 1: 0ms - 2756ms (原时长: 3500ms, 加速后: 2756ms)
  字幕 2: 2756ms - 6063ms (原时长: 4200ms, 加速后: 3307ms)
  ...
  
  最终总时长: 115000ms (目标: 115000ms)
  误差: 0ms

🔗 根据动态时间轴合并音频...
  字幕 1: 加速音频 1.27x (3500ms -> 2756ms)
    ✅ 加速成功，实际时长: 2756ms
  字幕 1: 添加配音 2756ms
  
  字幕 2: 加速音频 1.27x (4200ms -> 3307ms)
    ✅ 加速成功，实际时长: 3307ms
  字幕 2: 添加配音 3307ms
  ...
  
  🔗 合并 N 个音频片段...
  💾 导出最终音频: dubbing_result.wav
  ✅ 最终音频时长: 115000ms (1.9分钟)
```

**输出**：
- `adjusted_subtitles.srt` - 总时长 1:55 ✅
- `dubbing_result.wav` - 总时长 1:55 ✅

### 场景2：配音短于原始时长（需要扩展间隙）

**输入**：
```
原始SRT总时长: 115000ms (1:55)
配音总时长: 95000ms (1:35)
静音间隙总时长: 5000ms
```

**处理过程**：
```
⏱️  开始动态调整时间轴
原始总时长: 115000ms

总配音时长: 95000ms
时长差异: -20000ms

  原始间隙总时长: 5000ms
  ✅ 扩展间隙，增加 20000ms
  
  字幕 1: 0ms - 2000ms (间隙: 0ms)
  字幕 2: 5000ms - 7500ms (间隙: 3000ms)
  ...
  
  最终总时长: 115000ms (目标: 115000ms)
  误差: 0ms
```

**输出**：
- `adjusted_subtitles.srt` - 总时长 1:55 ✅
- `dubbing_result.wav` - 总时长 1:55 ✅

## 🧪 测试步骤

### 1. 准备测试数据

创建一个测试SRT文件 `test.srt`：
```srt
1
00:00:00,000 --> 00:00:02,000
第一句话

2
00:00:02,500 --> 00:00:05,000
第二句话

3
00:00:05,500 --> 00:00:08,000
第三句话
```

总时长：8000ms (8秒)

### 2. 启动后端服务

```bash
cd pyannote-audio-web-ui/src
python main.py
```

### 3. 测试API调用

```python
import requests

# 准备参数
data = {
    'engine': 'gpt-sovits',
    'role': {
        'refAudioPath': 'path/to/reference.mp3',
        'promptText': '参考文本',
        'promptLang': 'zh'
    },
    'text_lang': 'ja',  # 日语配音（通常更长）
    'speed_factor': 1.0,
    'enable_smart_speedup': True,  # 启用智能加速
    'preserve_total_time': True,   # 保持总时长不变
}

# 上传SRT文件
files = {'srt_file': open('test.srt', 'rb')}

# 发送请求
response = requests.post(
    'http://localhost:8514/api/tts-dubbing/start',
    data=data,
    files=files
)

print(response.json())
```

### 4. 检查输出

查看输出目录中的文件：
- `adjusted_subtitles.srt` - 检查总时长是否为 8秒
- `dubbing_result.wav` - 检查音频时长是否为 8秒

### 5. 查看日志

检查控制台输出，应该看到类似的日志：
```
⏱️  开始动态调整时间轴
原始总时长: 8000ms
...
🚀 需要加速配音以压缩 XXXms
📊 加速倍率: X.XXx
...
✅ 最终音频时长: 8000ms (8.0秒)
```

## 🎯 验证要点

1. **时间轴调整**：
   - `adjusted_subtitles.srt` 的最后一句结束时间 = 原始SRT的最后一句结束时间
   - 字幕之间的间隙被压缩或扩展

2. **音频加速**：
   - 日志中显示 "加速音频 X.XXx"
   - 每段音频的实际时长 = adjusted_duration_ms

3. **最终输出**：
   - `dubbing_result.wav` 的时长 = 原始SRT总时长
   - 音频质量良好（使用FFmpeg高质量加速）

## 🐛 可能的问题

### 问题1：FFmpeg加速失败

**症状**：
```
⚠️ FFmpeg加速失败，使用pydub备选方案
```

**原因**：
- FFmpeg未安装或不在PATH中
- rubberband滤镜不可用

**解决**：
- 安装FFmpeg：`choco install ffmpeg`（Windows）
- 或使用pydub的speedup（质量稍差）

### 问题2：最终时长仍然不匹配

**症状**：
```
最终总时长: 120000ms (目标: 115000ms)
误差: +5000ms
```

**原因**：
- 加速倍率计算有误差
- 音频截断/填充逻辑未生效

**解决**：
- 检查 `_merge_audio_with_timeline` 中的音频时长调整逻辑
- 确保 `original_duration_ms` 和 `adjusted_duration_ms` 正确传递

### 问题3：音频质量下降

**症状**：
- 音频听起来失真或不自然

**原因**：
- 加速倍率过高（> 2.0x）
- 使用了pydub的speedup而不是FFmpeg

**解决**：
- 降低 `max_audio_speed_rate` 参数
- 确保FFmpeg可用
- 考虑使用 `SimpleTimelineBuilder` 模式

## 📝 总结

修复后的"保持总时长不变"功能：

✅ **正确处理配音超出原始时长的情况**
✅ **自动加速配音以匹配原始SRT总时长**
✅ **输出调整后的SRT文件和音频文件**
✅ **使用FFmpeg高质量音频加速**
✅ **保证最终输出时长 = 原始SRT总时长**

现在你可以：
1. 上传原始SRT文件（如 1:55）
2. 启用"保持总时长不变"
3. 获得调整后的SRT文件（1:55）和音频文件（1:55）
4. 即使配音实际时长更长（如 2:32），也会自动加速到 1:55
