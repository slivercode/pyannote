# 动态时间轴调整功能集成完成说明

## 📋 功能概述

成功集成了**动态时间轴调整**功能，解决了智能音频加速后音画不同步的问题。

### 核心特性
- ✅ 根据实际生成的音频长度动态调整字幕时间轴
- ✅ 保证SRT总时长不变（与原始SRT一致）
- ✅ 通过智能压缩/扩展静音间隙来吸收时长差异
- ✅ 支持单角色和多角色配音模式

---

## 🎯 解决的问题

### 问题描述
之前启用智能音频加速后，虽然音频被压缩了，但字幕时间轴没有相应调整，导致：
- 音频和字幕不同步
- 最终音频总时长与原始SRT不一致
- 配音与视频画面对不上

### 解决方案
新增 `TimelineAdjuster` 类，实现三种调整策略：

1. **简单调整**：直接按实际配音时长排列（差异很小时）
2. **压缩时间轴**：配音超出原始时长时，按比例压缩静音间隙
3. **扩展时间轴**：配音短于原始时长时，按比例扩展静音间隙

---

## 📁 修改的文件

### 1. 后端核心逻辑

#### `timeline_adjuster.py` (新增)
- 时间轴动态调整器
- 实现三种调整策略
- 保证总时长不变

#### `tts_dubbing_processor.py` (修改)
- 导入 `TimelineAdjuster`
- 新增 `preserve_total_time` 参数（默认 `True`）
- 新增 `_merge_audio_with_timeline()` 方法
- 在 `process()` 方法中集成时间轴调整逻辑

#### `tts_multi_role_dubbing.py` (修改)
- 新增 `preserve_total_time` 参数
- 传递给父类 `TTSDubbingProcessor`

### 2. 后端API接口

#### `main.py` (修改)
- `/api/tts-dubbing/start` 接口新增 `preserve_total_time` 参数（默认 `True`）
- `/api/tts-dubbing/multi-role` 接口新增 `preserve_total_time` 参数（默认 `True`）
- 传递参数到处理器

### 3. 前端界面

#### `index.html` (修改)
- **单角色配音区域**：新增"保持SRT总时长不变"复选框
- **多角色配音区域**：新增"保持SRT总时长不变"复选框
- Vue数据模型新增 `preserveTotalTime: true` 字段
- API调用时发送 `preserve_total_time` 参数

---

## 🔧 使用方法

### 1. 启用动态时间轴调整

在配音界面中：

1. ✅ 勾选"启用智能音频加速（推荐）"
2. 🎚️ 调整"最大加速倍率"（建议 1.5x-2.0x）
3. ✅ 勾选"保持SRT总时长不变（推荐）" ← **新增选项**

### 2. 工作流程

```
1. 上传SRT字幕文件
   ↓
2. 配置TTS引擎和角色
   ↓
3. 启用智能音频加速 + 保持总时长
   ↓
4. 开始配音
   ↓
5. 系统自动：
   - 生成每段配音
   - 计算实际音频时长
   - 动态调整字幕时间轴
   - 压缩/扩展静音间隙
   - 确保总时长不变
   ↓
6. 输出：
   - dubbing_result.wav（最终音频）
   - updated_subtitles.srt（更新后的字幕）
```

---

## 📊 调整策略详解

### 策略1：简单调整
**触发条件**：时长差异 < 10ms

```
直接按实际配音时长排列，保留原始间隙比例
```

### 策略2：压缩时间轴
**触发条件**：配音总时长 > 原始SRT总时长

```
1. 计算所有静音间隙总时长
2. 按比例压缩每个间隙
3. 如果间隙不足，允许字幕紧密排列
```

**示例**：
```
原始：[字幕1: 2000ms] [间隙: 500ms] [字幕2: 2500ms] [间隙: 1000ms] [字幕3: 2000ms]
配音：[音频1: 2500ms]                [音频2: 3000ms]                [音频3: 2200ms]
调整：[音频1: 2500ms] [间隙: 300ms] [音频2: 3000ms] [间隙: 600ms]  [音频3: 2200ms]
      ↑ 超出500ms                    ↑ 超出500ms                    ↑ 超出200ms
      总超出: 1200ms → 压缩间隙: 1500ms → 300ms (减少1200ms)
```

### 策略3：扩展时间轴
**触发条件**：配音总时长 < 原始SRT总时长

```
1. 计算所有静音间隙总时长
2. 按比例扩展每个间隙
3. 确保最终总时长等于原始总时长
```

**示例**：
```
原始：[字幕1: 2000ms] [间隙: 500ms] [字幕2: 2500ms] [间隙: 1000ms] [字幕3: 2000ms]
配音：[音频1: 1800ms]                [音频2: 2200ms]                [音频3: 1900ms]
调整：[音频1: 1800ms] [间隙: 600ms] [音频2: 2200ms] [间隙: 1200ms] [音频3: 1900ms]
      ↑ 短200ms                      ↑ 短300ms                      ↑ 短100ms
      总短: 600ms → 扩展间隙: 1500ms → 2100ms (增加600ms)
```

---

## 🎨 界面变化

### 单角色配音界面

```
┌─────────────────────────────────────────┐
│ ☑ 启用智能音频加速（推荐）              │
│   自动调整音频速度以匹配字幕时长        │
│                                         │
│ ┌─────────────────────────────────────┐ │
│ │ 最大加速倍率: 2.0x                  │ │
│ │ ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ │ │
│ │ 1.0x    建议: 1.5x-2.0x        2.5x │ │
│ │                                     │ │
│ │ ─────────────────────────────────── │ │
│ │ ☑ 保持SRT总时长不变（推荐）← 新增   │ │
│ │   动态调整字幕时间轴，确保最终音频  │ │
│ │   时长与原始SRT一致                 │ │
│ └─────────────────────────────────────┘ │
└─────────────────────────────────────────┘
```

---

## 🔍 技术细节

### TimelineAdjuster 类

```python
class TimelineAdjuster:
    def __init__(self, subtitles, audio_files, preserve_total_time=True):
        """
        Args:
            subtitles: 字幕列表 [{'start_ms': int, 'end_ms': int, 'text': str}, ...]
            audio_files: 配音文件列表
            preserve_total_time: 是否保持总时长不变
        """
    
    def adjust_timeline(self) -> List[Dict]:
        """
        动态调整时间轴
        
        Returns:
            更新后的字幕列表
        """
```

### 调整流程

```python
# 1. 获取每段配音的实际时长
actual_durations = [get_audio_duration(f) for f in audio_files]

# 2. 计算总时长差异
time_diff = sum(actual_durations) - original_total_time

# 3. 根据差异选择策略
if abs(time_diff) < 10:
    return simple_adjustment()
elif time_diff > 0:
    return compress_timeline(time_diff)
else:
    return expand_timeline(abs(time_diff))
```

---

## ✅ 测试建议

### 测试场景1：配音超出原始时长
```
原始SRT: 10秒
配音总时长: 12秒（超出2秒）
预期结果: 压缩静音间隙，最终音频仍为10秒
```

### 测试场景2：配音短于原始时长
```
原始SRT: 10秒
配音总时长: 8秒（短2秒）
预期结果: 扩展静音间隙，最终音频仍为10秒
```

### 测试场景3：多角色配音
```
原始SRT: 15秒，3个角色
配音总时长: 16秒（超出1秒）
预期结果: 按比例调整，最终音频仍为15秒
```

---

## 📝 注意事项

1. **默认启用**：`preserve_total_time` 默认为 `True`，建议保持启用
2. **与智能加速配合**：只有启用智能音频加速时，才会显示"保持总时长"选项
3. **间隙压缩限制**：如果静音间隙不足以吸收超出的时长，会允许字幕紧密排列
4. **音质影响**：过度压缩可能影响音质，建议配合合理的最大加速倍率使用

---

## 🚀 后续优化建议

1. **智能间隙分配**：根据语义边界智能分配间隙（句子间 > 词语间）
2. **音频质量检测**：自动检测压缩后的音质，超过阈值时提示用户
3. **可视化预览**：在界面上显示调整前后的时间轴对比
4. **批量处理**：支持批量处理多个SRT文件

---

## 📞 问题反馈

如遇到问题，请检查：
1. 是否启用了"智能音频加速"
2. 是否勾选了"保持SRT总时长不变"
3. 查看控制台日志中的时间轴调整详情
4. 检查 `updated_subtitles.srt` 文件的时间轴是否正确

---

**更新时间**: 2025-12-15
**版本**: v1.0
**状态**: ✅ 已完成并集成
