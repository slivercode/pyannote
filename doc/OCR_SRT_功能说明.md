# OCR字幕说话人分配功能说明

## 功能概述

新增功能允许用户上传视频文件（MP4等）和通过OCR识别的SRT字幕文件，系统会使用pyannote自动识别视频中的说话人，并将字幕内容分配给对应的说话人。

## 主要特点

1. **支持视频格式**：MP4, AVI, MOV, MKV
2. **支持字幕格式**：SRT（标准字幕格式）
3. **自动说话人识别**：使用pyannote-audio进行说话人分割
4. **智能字幕分配**：根据时间轴自动匹配字幕和说话人
5. **多种输出格式**：JSON和SRT格式

## 文件结构

### 1. 后端处理脚本
**文件路径**: `src/scripts/ocr_srt_speaker_assignment.py`

**主要功能**:
- 解析SRT字幕文件
- 使用pyannote进行说话人分割
- 将字幕分配给对应的说话人
- 生成按说话人分组的字幕文件

**核心函数**:
- `parse_srt_file()`: 解析SRT字幕文件
- `assign_speakers_to_subtitles()`: 将说话人分配给字幕
- `process_video_with_srt()`: 主处理流程

### 2. 前端界面
**文件路径**: `src/static/ocr_srt_speaker.html`

**主要功能**:
- 视频文件上传/路径输入
- SRT字幕文件上传/路径输入
- 说话人数量配置
- 实时进度显示
- 结果展示和文件夹打开

### 3. API接口
**文件路径**: `src/main.py`

**新增接口**:
- `POST /api/upload-video`: 上传视频文件
- `POST /api/upload-srt`: 上传SRT字幕文件

## 使用方法

### 方式一：文件上传

1. 访问主页，点击"OCR字幕说话人分配"标签
2. 点击"上传视频"按钮，选择视频文件
3. 点击"上传字幕"按钮，选择SRT字幕文件
4. （可选）设置说话人数量或范围
5. 点击"开始处理"按钮

### 方式二：路径输入

1. 访问主页，点击"OCR字幕说话人分配"标签
2. 在"视频文件路径"输入框中输入视频文件的完整路径
   - 例如：`D:\download\video\target.mp4`
3. 在"SRT字幕路径"输入框中输入字幕文件的完整路径
   - 例如：`D:\download\video\subtitle.srt`
4. （可选）设置说话人数量或范围
5. 点击"开始处理"按钮

### 说话人数量配置

- **固定数量**：如果确切知道有几个说话人，填写"说话人数量"
- **数量范围**：如果不确定，可以设置最小值和最大值
- **自动检测**：全部填0，系统自动检测

## 输出结果

处理完成后，会在`output`目录下生成以下文件：

```
output/
└── [视频文件名]/
    ├── 字幕说话人分配结果.json          # 完整的分配结果
    └── speaker_subtitles/               # 按说话人分组的字幕
        ├── spk00_字幕.json              # 说话人0的字幕（JSON格式）
        ├── spk00_字幕.srt               # 说话人0的字幕（SRT格式）
        ├── spk01_字幕.json              # 说话人1的字幕（JSON格式）
        ├── spk01_字幕.srt               # 说话人1的字幕（SRT格式）
        └── ...
```

### 输出文件说明

1. **字幕说话人分配结果.json**
   - 包含所有字幕条目
   - 每条包含：开始时间、结束时间、持续时间、说话人、文本内容

2. **spkXX_字幕.json**
   - 单个说话人的所有字幕（JSON格式）
   - 便于程序处理

3. **spkXX_字幕.srt**
   - 单个说话人的所有字幕（标准SRT格式）
   - 可直接用于视频播放器

## SRT字幕格式要求

标准SRT格式示例：

```
1
00:00:01,000 --> 00:00:03,500
这是第一句字幕

2
00:00:04,000 --> 00:00:06,500
这是第二句字幕

3
00:00:07,000 --> 00:00:09,500
这是第三句字幕
```

**格式要求**:
- 每个字幕块包含：序号、时间轴、文本内容
- 时间格式：`HH:MM:SS,mmm --> HH:MM:SS,mmm`
- 字幕块之间用空行分隔

## 技术原理

1. **SRT解析**：使用正则表达式解析SRT文件，提取时间轴和文本
2. **音频提取**：从视频中提取音频轨道
3. **说话人分割**：使用pyannote-audio进行说话人分割
4. **时间匹配**：计算字幕时间段与说话人时间段的重叠度
5. **说话人分配**：将字幕分配给重叠度最高的说话人
6. **结果输出**：生成JSON和SRT格式的分组字幕

## 注意事项

1. **文件路径**：
   - 路径中不要包含特殊字符（#、&、空格等）
   - 使用反斜杠`\`或正斜杠`/`均可

2. **字幕质量**：
   - OCR识别的字幕应尽量准确
   - 时间轴应与视频同步

3. **说话人识别**：
   - 如果说话人有明显的声音特征差异，识别效果更好
   - 背景噪音会影响识别准确度

4. **处理时间**：
   - 处理时间取决于视频长度和说话人数量
   - 长视频可能需要几分钟到十几分钟

## 导航

- 从主页访问：点击顶部"OCR字幕说话人分配"标签
- 返回主页：点击"长音频或批量（无多人声重叠）"标签
- 访问合并工具：点击"工具-音(视)频合并"标签

## 技术栈

- **后端**: Python, FastAPI, pyannote-audio
- **前端**: Vue 3, Tailwind CSS, Axios
- **音频处理**: FFmpeg, soundfile
- **说话人识别**: pyannote-audio (Hugging Face)
