# 新功能：TTS生成时自动调整语速

## 功能概述

新增功能：在TTS生成语音时，根据字幕的时间轴自动调整每条语音的语速，使生成的配音时长精确匹配字幕时长。

## 工作原理

### 传统方式（之前）
```
1. TTS用固定语速生成所有配音
2. 生成后测量每条配音的实际时长
3. 如果时长不匹配，后期加速/减速调整
```

**问题：**
- 后期加速可能影响音质
- 无法精确控制每条配音的时长
- 需要额外的处理步骤

### 新方式（现在）
```
1. 读取字幕的起止时间，计算目标时长
2. TTS生成时先用标准语速测试
3. 根据测试结果计算需要的语速
4. 用计算后的语速重新生成
5. 生成的配音直接匹配字幕时长
```

**优势：**
- ✅ TTS生成时就调整语速，音质更好
- ✅ 每条配音精确匹配字幕时长
- ✅ 减少后期处理
- ✅ 更精确的时间轴对齐

## 使用方法

### 启用条件

当同时满足以下条件时，自动启用：
1. 勾选"自动对齐时间轴"
2. 系统会自动为每条字幕计算目标时长

### 界面配置

```
┌─────────────────────────────────────┐
│ ☑ 自动对齐时间轴                   │
│ (勾选后自动启用智能语速调整)        │
├─────────────────────────────────────┤
│ TTS生成语速: 1.0x                   │
│ (作为基准语速，实际会自动调整)      │
└─────────────────────────────────────┘
```

## 处理流程

### 步骤1：解析字幕时间轴
```python
字幕1: 00:00:00,000 --> 00:00:02,000  # 目标时长: 2000ms
字幕2: 00:00:02,500 --> 00:00:05,300  # 目标时长: 2800ms
字幕3: 00:00:06,000 --> 00:00:06,900  # 目标时长: 900ms
```

### 步骤2：为每条字幕生成配音

**字幕1（目标2000ms）：**
```
1. 用1.0x语速测试生成 → 实际2500ms
2. 计算需要的语速: 2500/2000 = 1.25x
3. 用1.25x语速重新生成 → 实际2000ms
4. ✅ 完美匹配
```

**字幕2（目标2800ms）：**
```
1. 用1.0x语速测试生成 → 实际3200ms
2. 计算需要的语速: 3200/2800 = 1.14x
3. 用1.14x语速重新生成 → 实际2800ms
4. ✅ 完美匹配
```

**字幕3（目标900ms）：**
```
1. 用1.0x语速测试生成 → 实际1800ms
2. 计算需要的语速: 1800/900 = 2.0x
3. 限制最大语速2.0x
4. 用2.0x语速生成 → 实际900ms
5. ✅ 完美匹配
```

### 步骤3：直接拼接
```
所有配音都已精确匹配字幕时长
直接按时间轴拼接即可
无需后期调整
```

## 语速限制

为了保护音质，系统会限制语速范围：

```
最小语速: 0.5x  (最慢)
最大语速: 2.0x  (最快)
```

如果计算出的语速超出范围：
- 超过2.0x：使用2.0x，配音会稍长
- 低于0.5x：使用0.5x，配音会稍短

## 日志输出

启用后，你会看到详细的处理日志：

```
📝 处理字幕 1/35: 何でだよ 私たちは治療を受けに来たんだよ...
🎭 使用角色配置: spk01
  📊 测试时长: 2500ms, 目标: 2000ms, 计算语速: 1.25x
🔄 调用GPT-SoVITS API [spk01, 语速=1.25x]: 何でだよ 私たちは治療を受けに来たんだよ...
✅ 语音合成成功: audio_0001.wav, 时长: 2000ms (目标: 2000ms)
```

## 性能考虑

### 额外开销
- 每条字幕需要生成两次（测试 + 正式）
- 处理时间约增加50%

### 优化建议
1. 仅在需要精确对齐时启用
2. 对于不重要的项目，可以不启用
3. 可以先测试几条字幕，确认效果后再全量处理

## 适用场景

### 推荐使用
✅ 需要精确对齐字幕和配音
✅ 字幕时长差异较大
✅ 对音质要求高
✅ 需要减少后期处理

### 不推荐使用
❌ 字幕时长都很合理
❌ 对处理速度要求高
❌ 不在意精确对齐

## 与其他功能的关系

### 与"保持SRT总时长不变"的关系
```
自动调整语速: 在TTS生成时调整每条配音
保持总时长: 在拼接时调整间隙和时间轴

两者可以配合使用：
1. TTS生成时调整语速 → 每条配音接近目标时长
2. 拼接时调整间隙 → 总时长精确匹配
```

### 与"TTS生成语速"的关系
```
TTS生成语速: 作为基准语速
自动调整: 在基准上微调

例如：
- 基准语速: 1.0x
- 字幕1需要: 1.2x (在1.0x基础上加速)
- 字幕2需要: 0.9x (在1.0x基础上减速)
```

## 配置示例

### 示例1：精确对齐（推荐）
```
TTS生成语速: 1.0x
☑ 自动对齐时间轴
☐ 保持SRT总时长不变

效果：
- 每条配音精确匹配字幕时长
- 总时长 = 配音时长 + 间隔
- 音质最佳
```

### 示例2：精确对齐 + 保持总时长
```
TTS生成语速: 1.0x
☑ 自动对齐时间轴
☑ 保持SRT总时长不变

效果：
- 每条配音精确匹配字幕时长
- 通过调整间隙保持总时长
- 最精确的控制
```

### 示例3：快速处理
```
TTS生成语速: 1.2x
☐ 自动对齐时间轴
☐ 保持SRT总时长不变

效果：
- 所有配音用1.2x语速
- 不做精确对齐
- 处理速度最快
```

## 技术细节

### 实现原理

```python
def _synthesize_gpt_sovits(self, text, output_path, speaker=None, target_duration_ms=None):
    if target_duration_ms and self.auto_align:
        # 1. 用标准语速测试生成
        test_audio = generate_with_speed(text, 1.0)
        actual_duration = measure_duration(test_audio)
        
        # 2. 计算需要的语速
        required_speed = actual_duration / target_duration_ms
        required_speed = clamp(required_speed, 0.5, 2.0)
        
        # 3. 用计算后的语速重新生成
        final_audio = generate_with_speed(text, required_speed)
        
        return final_audio
```

### 语速计算公式

```
需要的语速 = 实际时长 / 目标时长

例如：
- 实际时长: 2500ms
- 目标时长: 2000ms
- 需要语速: 2500 / 2000 = 1.25x
```

## 总结

这个新功能让TTS生成更智能：
1. ✅ 自动调整每条配音的语速
2. ✅ 精确匹配字幕时间轴
3. ✅ 减少后期处理
4. ✅ 保持更好的音质

**使用建议：**
- 需要精确对齐时启用
- 配合"保持SRT总时长"使用效果最佳
- 注意处理时间会增加约50%

---

*更新日期：2024-12-16*
*相关代码：src/scripts/tts_dubbing_processor.py*