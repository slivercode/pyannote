"""
å¤šè§’è‰²TTSé…éŸ³å¤„ç†å™¨ï¼ˆåŸºäºå¸¦è¯´è¯äººæ ‡è¯†çš„SRTï¼‰
è‡ªåŠ¨è§£æSRTä¸­çš„è§’è‰²æ ‡è¯†ï¼ŒæŒ‰è§’è‰²åˆ†é…ä¸åŒçš„TTSé…éŸ³
"""

import os
import re
import json
import sys
from pathlib import Path
from collections import defaultdict

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
current_script_dir = os.path.dirname(os.path.abspath(__file__))
if current_script_dir not in sys.path:
    sys.path.insert(0, current_script_dir)

from tts_dubbing_processor import TTSDubbingProcessor


class MultiRoleDubbingProcessor(TTSDubbingProcessor):
    """å¤šè§’è‰²é…éŸ³å¤„ç†å™¨"""
    
    def __init__(self, srt_path, output_dir, engine, roles_config, 
                 text_lang='zh', speed_factor=1.0, silence_duration=0.5, 
                 auto_align=True, api_url=None, api_key=None, 
                 task_id=None, task_dict=None,
                 enable_smart_speedup=False, enable_audio_speedup=True,
                 enable_video_slowdown=False, max_audio_speed_rate=2.0,
                 max_video_pts_rate=10.0, remove_silent_gaps=False,
                 preserve_total_time=False):  # é»˜è®¤ä¸ä¿æŒæ€»æ—¶é•¿ï¼Œä¿æŒåŸå§‹é—´éš”
        """
        åˆå§‹åŒ–å¤šè§’è‰²é…éŸ³å¤„ç†å™¨
        
        Args:
            srt_path: å¸¦è¯´è¯äººæ ‡è¯†çš„SRTæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            engine: TTSå¼•æ“ ('gpt-sovits' æˆ– 'qwen-tts')
            roles_config: è§’è‰²é…ç½®å­—å…¸ {è§’è‰²å: è§’è‰²é…ç½®æ•°æ®}
                ä¾‹å¦‚: {
                    "spk00": {"refAudioPath": "...", "promptText": "...", ...},
                    "spk01": {"refAudioPath": "...", "promptText": "...", ...}
                }
            text_lang: åˆæˆè¯­è¨€ ('zh', 'en', 'ja', 'ko')
            speed_factor: è¯­é€Ÿç³»æ•°
            silence_duration: é™éŸ³é—´éš”æ—¶é•¿(ç§’)
            auto_align: æ˜¯å¦è‡ªåŠ¨å¯¹é½æ—¶é—´è½´
            api_url: GPT-SoVITS APIåœ°å€
            api_key: QwenTTS APIå¯†é’¥
            task_id: ä»»åŠ¡ID
            task_dict: ä»»åŠ¡çŠ¶æ€å­—å…¸
        """
        # ä¸ä¼ é€’å•ä¸ªrole_dataï¼Œä½¿ç”¨roles_config
        super().__init__(
            srt_path=srt_path,
            output_dir=output_dir,
            engine=engine,
            role_data={},  # ä¸´æ—¶ç©ºå­—å…¸
            text_lang=text_lang,
            speed_factor=speed_factor,
            silence_duration=silence_duration,
            auto_align=auto_align,
            api_url=api_url,
            api_key=api_key,
            task_id=task_id,
            task_dict=task_dict,
            # æ–°å¢ï¼šæ™ºèƒ½åŒé‡å˜é€Ÿæœºåˆ¶å‚æ•°
            enable_smart_speedup=enable_smart_speedup,
            enable_audio_speedup=enable_audio_speedup,
            enable_video_slowdown=enable_video_slowdown,
            max_audio_speed_rate=max_audio_speed_rate,
            max_video_pts_rate=max_video_pts_rate,
            remove_silent_gaps=remove_silent_gaps,
            preserve_total_time=preserve_total_time
        )
        
        self.roles_config = roles_config  # {spk00: {...}, spk01: {...}}
        self.speaker_stats = defaultdict(int)  # ç»Ÿè®¡æ¯ä¸ªè§’è‰²çš„å­—å¹•æ•°
        
    def parse_srt_with_speakers(self):
        """
        è§£æå¸¦è¯´è¯äººæ ‡è¯†çš„SRTæ–‡ä»¶
        
        Returns:
            List[Dict]: [{
                'index': 1,
                'start': '00:00:00,000',
                'end': '00:00:03,500',
                'speaker': 'spk00',
                'text': 'å¤§å®¶å¥½ï¼Œæ¬¢è¿æ”¶çœ‹ä»Šå¤©çš„èŠ‚ç›®'
            }, ...]
        """
        print(f"ğŸ“– å¼€å§‹è§£æå¸¦è¯´è¯äººæ ‡è¯†çš„SRTæ–‡ä»¶: {self.srt_path}")
        
        with open(self.srt_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print(f"ğŸ“„ æ–‡ä»¶å¤§å°: {len(content)} å­—ç¬¦")
        
        # è°ƒè¯•ï¼šæ‰“å°æ–‡ä»¶å‰500ä¸ªå­—ç¬¦
        print(f"ğŸ“ æ–‡ä»¶å‰500å­—ç¬¦é¢„è§ˆ:")
        print("-" * 50)
        print(content[:500])
        print("-" * 50)
        
        subtitles = []
        # æ ‡å‡†åŒ–æ¢è¡Œç¬¦ï¼ˆæ³¨æ„ï¼šæŸäº›æ–‡ä»¶å¯èƒ½ä½¿ç”¨ \r\r\nï¼‰
        content_normalized = content.replace('\r\r\n', '\n').replace('\r\n', '\n').replace('\r', '\n')
        
        # è°ƒè¯•ï¼šæ˜¾ç¤ºæ ‡å‡†åŒ–åçš„å‰500å­—ç¬¦
        print(f"ğŸ” æ ‡å‡†åŒ–åå‰500å­—ç¬¦:")
        print("-" * 50)
        print(repr(content_normalized[:500]))
        print("-" * 50)
        
        # ä½¿ç”¨æ›´çµæ´»çš„åˆ†å‰²æ–¹å¼ï¼šæŒ‰3ä¸ªæˆ–æ›´å¤šæ¢è¡Œç¬¦åˆ†å‰²ï¼ˆå³ç©ºè¡Œï¼‰
        # å› ä¸ºæ¯è¡Œç»“å°¾æ˜¯ \n\nï¼Œç©ºè¡Œæ˜¯ \n\n\n\nï¼Œæ‰€ä»¥ç”¨ \n{3,} æ¥åˆ†å‰²
        blocks = re.split(r'\n{3,}', content_normalized.strip())
        
        print(f"ğŸ“¦ åˆ†å‰²åçš„å—æ•°: {len(blocks)}")
        
        # è°ƒè¯•ï¼šæ˜¾ç¤ºå‰3ä¸ªå—
        for i in range(min(3, len(blocks))):
            print(f"ğŸ” å— {i+1}: {repr(blocks[i])}")
        
        # è¯´è¯äººæ ‡è¯†æ­£åˆ™ï¼š[spk00] æˆ– [SPEAKER_00] æˆ–ä»»æ„æ–¹æ‹¬å·å†…å®¹
        speaker_pattern = re.compile(r'^\[([^\]]+)\]\s*(.*)$')
        
        # æ—¶é—´è½´æ­£åˆ™
        time_pattern = re.compile(r'(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})')
        
        for i, block in enumerate(blocks):
            block = block.strip()
            if not block:
                continue
            
            lines = [line.strip() for line in block.split('\n') if line.strip()]
            
            # è‡³å°‘éœ€è¦ï¼šåºå·ã€æ—¶é—´è½´ã€æ–‡æœ¬
            if len(lines) < 3:
                if len(lines) > 0:
                    print(f"âš ï¸ å— {i+1} è¡Œæ•°ä¸è¶³ ({len(lines)} < 3)ï¼Œå†…å®¹: {lines}")
                continue
            
            # å°è¯•è§£æåºå·ï¼ˆç¬¬ä¸€è¡Œåº”è¯¥æ˜¯æ•°å­—ï¼‰
            try:
                index = int(lines[0])
            except ValueError:
                print(f"âš ï¸ å— {i+1} åºå·è§£æå¤±è´¥: {lines[0]}")
                continue
            
            # æŸ¥æ‰¾æ—¶é—´è½´ï¼ˆå¯èƒ½åœ¨ç¬¬2è¡Œæˆ–ç¬¬3è¡Œï¼‰
            time_match = None
            time_line_idx = -1
            for idx in range(1, min(3, len(lines))):
                time_match = time_pattern.match(lines[idx])
                if time_match:
                    time_line_idx = idx
                    break
            
            if not time_match:
                print(f"âš ï¸ å— {i+1} æœªæ‰¾åˆ°æ—¶é—´è½´ï¼Œå‰3è¡Œ: {lines[:3]}")
                continue
            
            # æå–æ–‡æœ¬ï¼ˆæ—¶é—´è½´ä¹‹åçš„æ‰€æœ‰è¡Œï¼‰
            text_lines = lines[time_line_idx + 1:]
            if not text_lines:
                print(f"âš ï¸ å— {i+1} æ²¡æœ‰æ–‡æœ¬å†…å®¹")
                continue
            
            # ç¬¬ä¸€è¡Œå¯èƒ½åŒ…å«è¯´è¯äººæ ‡è¯†
            first_line = text_lines[0]
            speaker_match = speaker_pattern.match(first_line)
            
            if speaker_match:
                # æœ‰è¯´è¯äººæ ‡è¯†
                speaker = speaker_match.group(1)
                text_parts = [speaker_match.group(2).strip()]
                # æ·»åŠ åç»­è¡Œï¼ˆå¦‚æœæœ‰å¤šè¡Œæ–‡æœ¬ï¼‰
                if len(text_lines) > 1:
                    text_parts.extend(text_lines[1:])
                text = '\n'.join([t for t in text_parts if t]).strip()
                
                # è°ƒè¯•ä¿¡æ¯
                if i < 3:  # åªæ‰“å°å‰3æ¡
                    print(f"  ğŸ” è°ƒè¯• - åŸå§‹è¡Œ: {first_line}")
                    print(f"  ğŸ” è°ƒè¯• - è¯´è¯äºº: {speaker}")
                    print(f"  ğŸ” è°ƒè¯• - æå–æ–‡æœ¬: {text}")
            else:
                # æ²¡æœ‰è¯´è¯äººæ ‡è¯†ï¼Œä½¿ç”¨é»˜è®¤
                speaker = 'default'
                text = '\n'.join(text_lines).strip()
                if i < 3:
                    print(f"  âš ï¸ è°ƒè¯• - æœªåŒ¹é…è¯´è¯äººï¼ŒåŸå§‹è¡Œ: {first_line}")
            
            # è·³è¿‡ç©ºæ–‡æœ¬
            if not text:
                print(f"âš ï¸ å— {i+1} æ–‡æœ¬ä¸ºç©º")
                continue
            
            subtitle = {
                'index': index,
                'start': time_match.group(1),
                'end': time_match.group(2),
                'speaker': speaker,
                'text': text
            }
            
            subtitles.append(subtitle)
            self.speaker_stats[speaker] += 1
            
            # åªæ‰“å°å‰10æ¡å’Œæ¯100æ¡
            if len(subtitles) <= 10 or len(subtitles) % 100 == 0:
                print(f"âœ… è§£æå­—å¹• {subtitle['index']}: [{speaker}] {text[:30]}...")
        
        print(f"\nâœ… è§£æå®Œæˆï¼Œå…± {len(subtitles)} æ¡å­—å¹•")
        print(f"ğŸ‘¥ è¯´è¯äººç»Ÿè®¡:")
        for speaker, count in sorted(self.speaker_stats.items()):
            print(f"  - {speaker}: {count} æ¡å­—å¹•")
        
        return subtitles
    
    def validate_roles_config(self):
        """éªŒè¯è§’è‰²é…ç½®æ˜¯å¦å®Œæ•´"""
        print("\nğŸ” éªŒè¯è§’è‰²é…ç½®...")
        
        missing_roles = []
        for speaker in self.speaker_stats.keys():
            if speaker not in self.roles_config and speaker != 'default':
                missing_roles.append(speaker)
        
        if missing_roles:
            print(f"âš ï¸ è­¦å‘Šï¼šä»¥ä¸‹è¯´è¯äººç¼ºå°‘é…éŸ³é…ç½®: {', '.join(missing_roles)}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰é»˜è®¤é…ç½®
            if 'default' in self.roles_config:
                print(f"   è¿™äº›å­—å¹•å°†ä½¿ç”¨é»˜è®¤é…ç½®")
            else:
                print(f"   âŒ é”™è¯¯ï¼šç¼ºå°‘é»˜è®¤é…ç½®ï¼Œæ— æ³•å¤„ç†è¿™äº›å­—å¹•")
                return False
        else:
            print(f"âœ… æ‰€æœ‰è¯´è¯äººå‡å·²é…ç½®")
        
        return True
    
    def synthesize_speech_with_role(self, text, speaker, index):
        """
        æ ¹æ®è¯´è¯äººè°ƒç”¨å¯¹åº”çš„TTSé…ç½®åˆæˆè¯­éŸ³
        
        Args:
            text: è¦åˆæˆçš„æ–‡æœ¬
            speaker: è¯´è¯äººæ ‡è¯†
            index: å­—å¹•ç´¢å¼•
            
        Returns:
            éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        """
        # è·å–è¯¥è¯´è¯äººçš„é…ç½®
        if speaker in self.roles_config:
            role_config = self.roles_config[speaker]
            print(f"  ğŸ­ ä½¿ç”¨è§’è‰²é…ç½®: {speaker}")
        elif 'default' in self.roles_config:
            role_config = self.roles_config['default']
            print(f"  âš ï¸ è¯´è¯äºº {speaker} æ— é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        else:
            raise ValueError(f"è¯´è¯äºº {speaker} ç¼ºå°‘é…éŸ³é…ç½®ï¼Œä¸”æ— é»˜è®¤é…ç½®")
        
        # ä¸´æ—¶è®¾ç½®å½“å‰è§’è‰²é…ç½®
        self.role_data = role_config
        
        # è°ƒç”¨çˆ¶ç±»çš„åˆæˆæ–¹æ³•
        return super().synthesize_speech(text, index)
    
    def process(self):
        """
        å¤„ç†å®Œæ•´çš„å¤šè§’è‰²é…éŸ³æµç¨‹
        
        Returns:
            dict: {
                'audio_path': str,  # æœ€ç»ˆéŸ³é¢‘æ–‡ä»¶è·¯å¾„
                'srt_path': str or None  # æ›´æ–°åçš„SRTæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæœ‰ï¼‰
            }
        """
        print("ğŸ¬ å¼€å§‹å¤šè§’è‰²TTSé…éŸ³å¤„ç†...")
        print(f"PROGRESS:5%")
        
        # è°ƒè¯•ä¿¡æ¯
        print(f"\nğŸ” è°ƒè¯•ä¿¡æ¯:")
        print(f"   preserve_total_time = {self.preserve_total_time}")
        print(f"   enable_smart_speedup = {self.enable_smart_speedup}")
        print(f"   auto_align = {self.auto_align}")
        
        # 1. è§£æå¸¦è¯´è¯äººæ ‡è¯†çš„SRTæ–‡ä»¶
        subtitles = self.parse_srt_with_speakers()
        total_subtitles = len(subtitles)
        
        if total_subtitles == 0:
            raise ValueError("SRTæ–‡ä»¶ä¸­æ²¡æœ‰å­—å¹•")
        
        # 1.5. æ™ºèƒ½è¯­é€Ÿä¼˜åŒ–ï¼šå¦‚æœå¯ç”¨ä¿æŒæ€»æ—¶é•¿ä¸”ä½¿ç”¨é»˜è®¤è¯­é€Ÿï¼Œè‡ªåŠ¨æå‡åˆ°1.2
        original_speed_factor = self.speed_factor
        if self.preserve_total_time and abs(self.speed_factor - 1.0) < 0.01:
            self.speed_factor = 1.2
            print(f"\nğŸš€ æ™ºèƒ½è¯­é€Ÿä¼˜åŒ–: {original_speed_factor} â†’ {self.speed_factor} (ä¿æŒæ€»æ—¶é•¿æ¨¡å¼)")
            print(f"   è¿™å°†åŠ å¿«TTSç”Ÿæˆé€Ÿåº¦ï¼Œå‡å°‘åæœŸè°ƒæ•´æ—¶é—´\n")
        
        print(f"PROGRESS:10%")
        
        # 2. éªŒè¯è§’è‰²é…ç½®
        if not self.validate_roles_config():
            raise ValueError("è§’è‰²é…ç½®éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        
        print(f"PROGRESS:15%")
        
        # 3. åˆæˆæ¯æ¡å­—å¹•çš„è¯­éŸ³
        audio_files = []
        subtitle_data = []
        
        for i, subtitle in enumerate(subtitles):
            # æ›´æ–°è¿›åº¦ (15% - 85%)
            progress = 15 + int((i / total_subtitles) * 70)
            print(f"PROGRESS:{progress}%")
            
            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
            self.update_progress(i, total_subtitles, subtitle)
            
            print(f"\nğŸ“ å¤„ç†å­—å¹• {i+1}/{total_subtitles}: [{subtitle['speaker']}] {subtitle['text'][:50]}...")
            
            # è·å–æ—¶é—´ä¿¡æ¯
            start_ms = self.time_to_ms(subtitle['start'])
            end_ms = self.time_to_ms(subtitle['end'])
            
            # ä½¿ç”¨å¯¹åº”è§’è‰²çš„é…ç½®åˆæˆè¯­éŸ³
            target_duration_ms = end_ms - start_ms
            
            try:
                audio_path = self.synthesize_speech_with_role(
                    subtitle['text'], 
                    subtitle['speaker'], 
                    i + 1
                )
                
                # æµ‹é‡å®é™…éŸ³é¢‘æ—¶é•¿
                from pydub import AudioSegment
                actual_audio = AudioSegment.from_file(audio_path)
                actual_duration_ms = len(actual_audio)
                synthesis_success = True
                
            except Exception as e:
                # TTSåˆæˆå¤±è´¥æ—¶ï¼Œç”Ÿæˆé™éŸ³å ä½éŸ³é¢‘ä»¥ä¿æŒæ—¶é—´è½´åŒæ­¥
                print(f"âš ï¸ å­—å¹• {i+1} åˆæˆå¤±è´¥ï¼Œè·³è¿‡: {e}")
                print(f"   ğŸ”‡ ç”Ÿæˆé™éŸ³å ä½éŸ³é¢‘ ({target_duration_ms}ms) ä»¥ä¿æŒæ—¶é—´è½´åŒæ­¥")
                
                # ç”Ÿæˆé™éŸ³å ä½éŸ³é¢‘
                from pydub import AudioSegment
                silence_audio = AudioSegment.silent(duration=target_duration_ms)
                audio_path = self.temp_dir / f"silence_{i+1:04d}.wav"
                silence_audio.export(str(audio_path), format="wav")
                audio_path = str(audio_path)
                
                actual_duration_ms = target_duration_ms
                synthesis_success = False
            
            # æ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½æ·»åŠ åˆ°åˆ—è¡¨ä¸­ä¿æŒç´¢å¼•å¯¹é½
            audio_files.append(audio_path)
            
            # æ„å»ºå­—å¹•æ•°æ®
            subtitle_data.append({
                'start_ms': start_ms,
                'end_ms': end_ms,
                'text': subtitle['text'],
                'audio_file': audio_path,
                'speaker': subtitle['speaker'],
                'original_duration_ms': target_duration_ms,  # åŸå§‹å­—å¹•æ—¶é•¿
                'actual_duration_ms': actual_duration_ms,    # å®é™…éŸ³é¢‘æ—¶é•¿
                'synthesis_success': synthesis_success       # æ ‡è®°æ˜¯å¦åˆæˆæˆåŠŸ
            })
        
        print(f"PROGRESS:85%")
        
        # 4. åˆ¤æ–­æ˜¯å¦ä½¿ç”¨ä¿æŒæ€»æ—¶é•¿åŠŸèƒ½
        if self.preserve_total_time:
            print("\nğŸš€ å¯ç”¨ä¿æŒSRTæ€»æ—¶é•¿ä¸å˜åŠŸèƒ½ï¼ˆå¤šè§’è‰²ï¼‰...")
            
            from timeline_adjuster import TimelineAdjuster
            
            print(f"ğŸ“Š TTSç”Ÿæˆè¯­é€Ÿ: {self.speed_factor}x")
            
            # ä½¿ç”¨TimelineAdjusteråŠ¨æ€è°ƒæ•´æ—¶é—´è½´
            timeline_adjuster = TimelineAdjuster(
                subtitles=subtitle_data,
                audio_files=audio_files,
                preserve_total_time=True,
                target_speed_factor=self.speed_factor,
                max_speed_limit=2.0
            )
            
            # è°ƒæ•´æ—¶é—´è½´
            updated_subtitles = timeline_adjuster.adjust_timeline()
            
            # æ ¹æ®æ›´æ–°åçš„æ—¶é—´è½´åˆå¹¶éŸ³é¢‘
            output_path = self._merge_audio_with_timeline_multi(updated_subtitles, audio_files)
            
            # ä¿å­˜æ›´æ–°åçš„å­—å¹•
            updated_srt_path = self._save_updated_srt_multi(updated_subtitles)
            
        else:
            # ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼æ‹¼æ¥éŸ³é¢‘
            print("\nğŸ”— æ‹¼æ¥éŸ³é¢‘ç‰‡æ®µï¼ˆä¼ ç»Ÿæ–¹å¼ï¼‰...")
            from pydub import AudioSegment
            
            audio_segments = []
            last_end_time = 0
            
            for i, subtitle_info in enumerate(subtitle_data):
                start_ms = subtitle_info['start_ms']
                end_ms = subtitle_info['end_ms']
                duration_ms = end_ms - start_ms
                
                # æ·»åŠ å­—å¹•å‰çš„é™éŸ³é—´éš™
                if start_ms > last_end_time:
                    silence_duration = start_ms - last_end_time
                    
                    if self.remove_silent_gaps:
                        # ç§»é™¤é™éŸ³é—´éš™æ¨¡å¼ï¼šåªä¿ç•™çŸ­æš‚çš„è‡ªç„¶åœé¡¿ï¼ˆæœ€å¤š300msï¼‰
                        natural_pause = min(silence_duration, 300)
                        if natural_pause > 0:
                            print(f"  â¸ï¸  æ·»åŠ è‡ªç„¶åœé¡¿: {natural_pause}ms")
                            audio_segments.append(self.create_silence(natural_pause))
                            last_end_time += natural_pause
                    else:
                        # ä¿ç•™æ—¶é—´è½´æ¨¡å¼ï¼šæ·»åŠ å®Œæ•´çš„é™éŸ³é—´éš™
                        print(f"  â¸ï¸  æ·»åŠ åŸå§‹é—´éš™: {silence_duration}ms")
                        audio_segments.append(self.create_silence(silence_duration))
                        last_end_time = start_ms
                
                # åŠ è½½éŸ³é¢‘
                audio = AudioSegment.from_wav(subtitle_info['audio_file'])
                
                # è‡ªåŠ¨å¯¹é½
                if self.auto_align:
                    audio_duration = len(audio)
                    if audio_duration > duration_ms:
                        speed_ratio = audio_duration / duration_ms
                        print(f"  âš¡ åŠ é€ŸéŸ³é¢‘: {speed_ratio:.2f}x")
                        audio = audio.speedup(playback_speed=speed_ratio)
                    elif audio_duration < duration_ms:
                        padding = duration_ms - audio_duration
                        print(f"  â¸ï¸  æ·»åŠ å°¾éƒ¨é™éŸ³: {padding}ms")
                        audio = audio + self.create_silence(padding)
                
                audio_segments.append(audio)
                last_end_time += len(audio)
                
                # æ·»åŠ å­—å¹•é—´éš”é™éŸ³ï¼ˆä»…åœ¨æ²¡æœ‰åŸå§‹é—´éš™æ—¶ï¼‰
                if not self.remove_silent_gaps and i < len(subtitle_data) - 1:
                    # æ£€æŸ¥ä¸‹ä¸€æ¡å­—å¹•æ˜¯å¦æœ‰åŸå§‹é—´éš™
                    next_subtitle = subtitle_data[i + 1]
                    next_start_ms = next_subtitle['start_ms']
                    
                    if next_start_ms <= end_ms:
                        # æ²¡æœ‰åŸå§‹é—´éš™ï¼Œæ·»åŠ é™éŸ³é—´éš”
                        silence_ms = int(self.silence_duration * 1000)
                        audio_segments.append(self.create_silence(silence_ms))
                        last_end_time += silence_ms
                        print(f"  â¸ï¸  æ·»åŠ å­—å¹•é—´éš”é™éŸ³: {silence_ms}ms")
                    # å¦‚æœæœ‰åŸå§‹é—´éš™ï¼Œä¼šåœ¨ä¸‹ä¸€æ¬¡å¾ªç¯å¼€å§‹æ—¶æ·»åŠ 
            
            # æ‹¼æ¥æ‰€æœ‰éŸ³é¢‘
            if not audio_segments:
                raise ValueError("æ²¡æœ‰éŸ³é¢‘ç‰‡æ®µå¯ä»¥æ‹¼æ¥")
            
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªç‰‡æ®µä½œä¸ºèµ·ç‚¹ï¼Œç„¶åé€ä¸ªæ‹¼æ¥
            final_audio = audio_segments[0]
            for segment in audio_segments[1:]:
                final_audio += segment
            
            # å¯¼å‡ºæœ€ç»ˆéŸ³é¢‘
            output_path = self.output_dir / "multi_role_dubbing_result.wav"
            print(f"ğŸ’¾ å¯¼å‡ºæœ€ç»ˆéŸ³é¢‘: {output_path}")
            final_audio.export(output_path, format="wav")
            output_path = str(output_path)
            
            # ç”Ÿæˆå­—å¹•æ–‡ä»¶
            updated_srt_path = None
            if self.remove_silent_gaps:
                # æ–¹æ¡ˆBï¼šåŸºäºå®é™…éŸ³é¢‘ç‰‡æ®µæ—¶é•¿ç”Ÿæˆç²¾ç¡®å­—å¹•ï¼ˆç§»é™¤é—´éš™ï¼‰
                updated_srt_path = self._generate_precise_subtitle_from_segments(
                    subtitle_data,
                    min_gap_ms=300  # ç‰‡æ®µä¹‹é—´ä¿ç•™300msé—´éš™
                )
            else:
                # æ–¹æ¡ˆDï¼šä¼ ç»Ÿæ¨¡å¼ - æ ¹æ®å®é™…æ‹¼æ¥çš„éŸ³é¢‘ç”Ÿæˆå­—å¹•
                updated_srt_path = self._generate_traditional_subtitle(
                    subtitle_data,
                    silence_duration_ms=int(self.silence_duration * 1000)
                )
        
        print(f"PROGRESS:90%")
        
        # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        print("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        for temp_file in self.temp_dir.glob("*.wav"):
            temp_file.unlink()
        
        # 6. ç»Ÿè®¡åˆæˆç»“æœ
        success_count = sum(1 for s in subtitle_data if s.get('synthesis_success', True))
        failed_count = len(subtitle_data) - success_count
        
        # 7. ä¿å­˜è§’è‰²ç»Ÿè®¡ä¿¡æ¯
        stats_path = self.output_dir / "role_stats.json"
        import json
        stats_data = {
            "total_subtitles": total_subtitles,
            "synthesis_success": success_count,
            "synthesis_failed": failed_count,
            "speakers": dict(self.speaker_stats),
            "output_file": str(output_path)
        }
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats_data, f, ensure_ascii=False, indent=2)
        
        print(f"PROGRESS:100%")
        
        print(f"\nâœ… å¤šè§’è‰²TTSé…éŸ³å®Œæˆï¼")
        print(f"   éŸ³é¢‘æ–‡ä»¶: {output_path}")
        print(f"   åˆæˆæˆåŠŸ: {success_count}/{total_subtitles} æ¡å­—å¹•")
        if failed_count > 0:
            print(f"   âš ï¸ åˆæˆå¤±è´¥: {failed_count} æ¡å­—å¹•ï¼ˆå·²ç”¨é™éŸ³å ä½ï¼Œæ—¶é—´è½´ä¿æŒåŒæ­¥ï¼‰")
        print(f"   ç»Ÿè®¡ä¿¡æ¯: {stats_path}")
        if updated_srt_path:
            print(f"   æ›´æ–°åçš„å­—å¹•: {updated_srt_path}")
        
        return {
            'audio_path': str(output_path),
            'srt_path': updated_srt_path
        }
    
    def _merge_audio_with_timeline_multi(self, updated_subtitles, audio_files):
        """
        æ ¹æ®æ›´æ–°åçš„æ—¶é—´è½´åˆå¹¶éŸ³é¢‘ï¼ˆå¤šè§’è‰²ç‰ˆæœ¬ï¼‰
        """
        print("\nğŸ”— æ ¹æ®åŠ¨æ€æ—¶é—´è½´åˆå¹¶éŸ³é¢‘ï¼ˆå¤šè§’è‰²ï¼‰...")
        
        from pydub import AudioSegment
        audio_segments = []
        current_time = 0
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå­˜æ”¾åŠ é€Ÿåçš„éŸ³é¢‘
        speedup_temp_dir = self.temp_dir / "speedup"
        speedup_temp_dir.mkdir(parents=True, exist_ok=True)
        
        for i, subtitle in enumerate(updated_subtitles):
            # æ·»åŠ å­—å¹•å‰çš„é™éŸ³é—´éš™
            if subtitle['start_ms'] > current_time:
                gap = subtitle['start_ms'] - current_time
                print(f"  å­—å¹• {i+1} å‰æ·»åŠ é™éŸ³: {gap}ms")
                audio_segments.append(AudioSegment.silent(duration=gap))
                current_time += gap
            
            # åŠ è½½é…éŸ³éŸ³é¢‘
            audio_file = audio_files[i] if i < len(audio_files) else None
            if audio_file and os.path.exists(audio_file):
                try:
                    audio = AudioSegment.from_file(audio_file)
                    audio_duration = len(audio)
                    
                    # è®¡ç®—ç›®æ ‡æ—¶é•¿
                    target_duration = subtitle['end_ms'] - subtitle['start_ms']
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦åŠ é€Ÿ
                    original_duration = subtitle.get('original_duration_ms', audio_duration)
                    adjusted_duration = subtitle.get('adjusted_duration_ms', target_duration)
                    
                    if original_duration > adjusted_duration and abs(original_duration - adjusted_duration) > 10:
                        speed_ratio = original_duration / adjusted_duration
                        print(f"  å­—å¹• {i+1}: åŠ é€ŸéŸ³é¢‘ {speed_ratio:.2f}x ({original_duration}ms -> {adjusted_duration}ms)")
                        
                        # ä½¿ç”¨pydubåŠ é€Ÿï¼ˆç®€å•æ–¹å¼ï¼‰
                        audio = audio.speedup(playback_speed=speed_ratio)
                    
                    # ç¡®ä¿éŸ³é¢‘æ—¶é•¿åŒ¹é…
                    actual_audio_duration = len(audio)
                    if abs(actual_audio_duration - target_duration) > 10:
                        if actual_audio_duration > target_duration:
                            audio = audio[:target_duration]
                        else:
                            padding = target_duration - actual_audio_duration
                            audio = audio + AudioSegment.silent(duration=padding)
                    
                    audio_segments.append(audio)
                    current_time += len(audio)
                    
                except Exception as e:
                    print(f"  âš ï¸ å­—å¹• {i+1} åŠ è½½éŸ³é¢‘å¤±è´¥: {e}ï¼Œä½¿ç”¨é™éŸ³")
                    silence_duration = subtitle['end_ms'] - subtitle['start_ms']
                    audio_segments.append(AudioSegment.silent(duration=silence_duration))
                    current_time += silence_duration
            else:
                silence_duration = subtitle['end_ms'] - subtitle['start_ms']
                print(f"  å­—å¹• {i+1}: ä½¿ç”¨é™éŸ³å¡«å…… {silence_duration}ms")
                audio_segments.append(AudioSegment.silent(duration=silence_duration))
                current_time += silence_duration
        
        # åˆå¹¶æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
        print(f"\n  ğŸ”— åˆå¹¶ {len(audio_segments)} ä¸ªéŸ³é¢‘ç‰‡æ®µ...")
        final_audio = sum(audio_segments)
        
        # å¯¼å‡ºæœ€ç»ˆéŸ³é¢‘
        output_path = self.output_dir / "multi_role_dubbing_result.wav"
        print(f"  ğŸ’¾ å¯¼å‡ºæœ€ç»ˆéŸ³é¢‘: {output_path}")
        final_audio.export(str(output_path), format="wav")
        
        print(f"  âœ… æœ€ç»ˆéŸ³é¢‘æ—¶é•¿: {len(final_audio)}ms ({len(final_audio)/1000:.1f}ç§’)")
        
        return str(output_path)
    
    def _save_updated_srt_multi(self, subtitles):
        """ä¿å­˜æ›´æ–°åçš„å­—å¹•æ–‡ä»¶ï¼ˆå¤šè§’è‰²ç‰ˆæœ¬ï¼‰"""
        output_srt = self.output_dir / "updated_subtitles.srt"
        
        with open(output_srt, 'w', encoding='utf-8') as f:
            for i, subtitle in enumerate(subtitles):
                f.write(f"{i+1}\n")
                
                # è½¬æ¢æ¯«ç§’ä¸ºSRTæ—¶é—´æ ¼å¼
                start_time = self._ms_to_srt_time(subtitle['start_ms'])
                end_time = self._ms_to_srt_time(subtitle['end_ms'])
                
                f.write(f"{start_time} --> {end_time}\n")
                
                # æ·»åŠ è¯´è¯äººæ ‡è®°
                speaker = subtitle.get('speaker', '')
                text = subtitle['text']
                if speaker:
                    text = f"[{speaker}] {text}"
                
                f.write(f"{text}\n\n")
        
        print(f"ğŸ’¾ ä¿å­˜æ›´æ–°åçš„å­—å¹•: {output_srt}")
        return str(output_srt)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="å¤šè§’è‰²TTSé…éŸ³å¤„ç†å™¨")
    parser.add_argument("--srt-path", required=True, help="å¸¦è¯´è¯äººæ ‡è¯†çš„SRTæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output-dir", required=True, help="è¾“å‡ºç›®å½•")
    parser.add_argument("--engine", required=True, choices=['gpt-sovits', 'qwen-tts'], help="TTSå¼•æ“")
    parser.add_argument("--roles-config", required=True, help="è§’è‰²é…ç½®JSONæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--text-lang", default='zh', help="åˆæˆè¯­è¨€")
    parser.add_argument("--speed-factor", type=float, default=1.0, help="è¯­é€Ÿç³»æ•°")
    parser.add_argument("--silence-duration", type=float, default=0.5, help="é™éŸ³é—´éš”æ—¶é•¿(ç§’)")
    parser.add_argument("--auto-align", action='store_true', default=True, help="è‡ªåŠ¨å¯¹é½æ—¶é—´è½´")
    parser.add_argument("--api-url", help="GPT-SoVITS APIåœ°å€")
    parser.add_argument("--api-key", help="QwenTTS APIå¯†é’¥")
    
    args = parser.parse_args()
    
    # åŠ è½½è§’è‰²é…ç½®
    with open(args.roles_config, 'r', encoding='utf-8') as f:
        roles_config = json.load(f)
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = MultiRoleDubbingProcessor(
        srt_path=args.srt_path,
        output_dir=args.output_dir,
        engine=args.engine,
        roles_config=roles_config,
        text_lang=args.text_lang,
        speed_factor=args.speed_factor,
        silence_duration=args.silence_duration,
        auto_align=args.auto_align,
        api_url=args.api_url,
        api_key=args.api_key
    )
    
    # æ‰§è¡Œå¤„ç†
    try:
        result = processor.process()
        print(f"\nâœ… å¤„ç†æˆåŠŸ: {result}")
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
